{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd40f4f4-5a80-40b7-94b3-aed136daa9d8",
   "metadata": {},
   "source": [
    "# Evaluate the Impact of Population-Weighting on Heat Wave Events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "27e597e9-538f-41d4-afa9-a268b10ab1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing the packages we need:\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f6fe5-0769-4298-887e-7c4cffc64a0d",
   "metadata": {},
   "source": [
    "## Set the Directory Structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd887600-32da-46dc-b411-fa63c75f564f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the data input and image output directories:\n",
    "service_territory_data_dir = '/Users/burl878/Documents/IMMM/Data/TELL/Production_Runs/tell_data/ba_service_territory_data/'\n",
    "population_data_dir = '/Users/burl878/Documents/IMMM/Data/TELL/Production_Runs/tell_data/population_data/'\n",
    "weather_data_dir =  '/Users/burl878/Documents/IMMM/Data/TELL/Production_Runs/tell_data/wrf_tell_counties_output/historic/'\n",
    "load_data_dir = '/Users/burl878/Documents/IMMM/Data/TELL/Production_Runs/tell_data/outputs/mlp_output/historic/'\n",
    "data_output_dir =  '/Users/burl878/Documents/Code/code_repos/nerc_analysis/data/'\n",
    "image_output_dir =  '/Users/burl878/Documents/Code/code_repos/nerc_analysis/plots/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7a320d-804a-44c4-b415-da9450d37344",
   "metadata": {},
   "source": [
    "## Process the Weather and Load Time Series by BA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "77098b53-9385-4a75-92af-f106f7715804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to process the load time series for a given BA and date range:\n",
    "def process_ba_load_time_series(ba_to_process: str, start_year: int, end_year: int, load_data_dir: str):\n",
    "    \n",
    "    # Loop over the years of load data:\n",
    "    for year in range(start_year, end_year, 1):\n",
    "        \n",
    "        # Read in the .csv file and replace missing values with nan:\n",
    "        mlp_data = pd.read_csv((load_data_dir + '/' + str(year) + '/' + ba_to_process + '_' + str(year) + '_mlp_output.csv')).replace(-9999, np.nan)\n",
    "\n",
    "        # Set the time variable as a datetime variable:\n",
    "        mlp_data['Time_UTC'] = pd.to_datetime(mlp_data['Time_UTC'])\n",
    "        \n",
    "        # Rename the \"BA\" variable:\n",
    "        mlp_data.rename(columns={'BA': 'BA_Code'}, inplace=True)\n",
    "\n",
    "        # Rename the \"Load\" variable:\n",
    "        mlp_data.rename(columns={'Load': 'Load_MWh'}, inplace=True)\n",
    "\n",
    "        # Replacing missing or negative loads with NaN:\n",
    "        mlp_data.loc[~(mlp_data['Load_MWh'] > 0), 'Load_MWh'] = np.nan\n",
    "\n",
    "        # Subset to just the variables we need:\n",
    "        mlp_data = mlp_data[['Time_UTC', 'Load_MWh']]\n",
    "    \n",
    "        # Aggregate the output into a new dataframe:\n",
    "        if year == start_year:\n",
    "           mlp_output_df = mlp_data\n",
    "        else:\n",
    "           mlp_output_df = pd.concat([mlp_output_df, mlp_data])\n",
    "        \n",
    "    return mlp_output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "56f141a5-13fe-436e-a241-1a7dd3808314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process the time series for a given BA and date range:\n",
    "def process_ba_time_series(ba_to_process: str, start_year: int, end_year: int, weather_data_dir: str, service_territory_data_dir: str, \n",
    "                           population_data_dir: str, load_data_dir: str, data_output_dir: str):\n",
    "    \n",
    "    # Read in the county-level population data:\n",
    "    pop_df = pd.read_csv(population_data_dir + 'county_populations_2000_to_2020.csv')\n",
    "\n",
    "    # Subset to just the variables we need:\n",
    "    pop_df = pop_df[['county_FIPS', 'pop_2019']]\n",
    "\n",
    "    # Rename the variables for simplicity:\n",
    "    pop_df.rename(columns={'county_FIPS': 'FIPS', 'pop_2019': 'Population'}, inplace=True)\n",
    "    \n",
    "    # Read in the BA-to-county mapping file:\n",
    "    mapping_df = pd.read_csv(service_territory_data_dir + 'ba_service_territory_2019.csv')\n",
    "    \n",
    "    # Subset to just the BA you want to process:\n",
    "    mapping_df = mapping_df.loc[(mapping_df['BA_Code'] == ba_to_process)]\n",
    "    \n",
    "    # Rename the variables for simplicity:\n",
    "    mapping_df.rename(columns={'County_FIPS': 'FIPS'}, inplace=True)\n",
    "    \n",
    "    # Subset to just the variables we need:\n",
    "    mapping_df = mapping_df[['BA_Code', 'FIPS']]\n",
    "    \n",
    "    # Initiate a counter to store the results:\n",
    "    counter = 0;\n",
    "    output_df = pd.DataFrame()\n",
    "    \n",
    "    # Loop over the years of weather data:\n",
    "    for year in range(start_year, end_year, 1):\n",
    "        \n",
    "        # Create a list of all county meteorology files in the input directory:\n",
    "        list_of_files = glob(os.path.join(weather_data_dir, str(year), '*.csv'))\n",
    "    \n",
    "        # Loop over that list process each file:\n",
    "        for file in range(len(list_of_files)):\n",
    "        # for file in range(1):\n",
    "            # Iterate the counter by one:\n",
    "            counter = counter + 1\n",
    "        \n",
    "            # Extract the filename from the list:\n",
    "            filename = list_of_files[file].rsplit('/', 1)[1]\n",
    "       \n",
    "            # Extract the time string from the name of the file:\n",
    "            filetime = filename.replace(\"_UTC_County_Mean_Meteorology.csv\", \"\")\n",
    "            \n",
    "            # Read in the .csv file:\n",
    "            met_df = pd.read_csv(list_of_files[file])\n",
    "            \n",
    "            # Convert the temperature from Kelvin to Fahrenheit:\n",
    "            met_df['T2'] = (1.8 * (met_df['T2'] - 273)) + 32\n",
    "        \n",
    "            # Merge the meteorology and population data into the mapping_df\n",
    "            ba_df = mapping_df.merge(met_df, on=['FIPS']).merge(pop_df, on=['FIPS'])\n",
    "        \n",
    "            # Compute the fraction of the total population in the BA that lives in a given county:\n",
    "            ba_df['Population_Fraction'] = ba_df['Population'] / (ba_df['Population'].sum())\n",
    "\n",
    "            # Population-weight T2:\n",
    "            ba_df['T2_Weighted'] = (ba_df['T2'].mul(ba_df['Population_Fraction']))\n",
    "       \n",
    "            # Add the time step to the output file:\n",
    "            output_df.loc[counter, 'Time_UTC'] = pd.to_datetime(filetime, exact=False, format='%Y_%m_%d_%H')\n",
    "            output_df.loc[counter, 'T2_UW'] = (ba_df['T2'].mean()).round(2)\n",
    "            output_df.loc[counter, 'T2_PW'] = (ba_df['T2_Weighted'].sum()).round(2)\n",
    "            output_df.loc[counter, 'T2_Min'] = ba_df['T2'].min().round(2)\n",
    "            output_df.loc[counter, 'T2_Max'] = ba_df['T2'].max().round(2)\n",
    "            \n",
    "            # Clean up the old dataframes and move to the next file in the loop:\n",
    "            del filename, filetime, met_df, ba_df\n",
    "        \n",
    "    # Sort by time:\n",
    "    output_df = output_df.sort_values(['Time_UTC'])\n",
    "    \n",
    "    # Aggregate the TELL MLP output for the BA and date range:\n",
    "    load_df = process_ba_load_time_series(ba_to_process = ba_to_process, \n",
    "                                          start_year = start_year, \n",
    "                                          end_year = end_year, \n",
    "                                          load_data_dir = load_data_dir)\n",
    "    \n",
    "    # Merge the meteorology and load data:\n",
    "    output_df = output_df.merge(load_df, on=['Time_UTC'])\n",
    "        \n",
    "    # Create the ouput filename:    \n",
    "    csv_output_filename = os.path.join(data_output_dir, (ba_to_process + '_Time_Series_' + str(start_year) + '_to_' + str(end_year) + '.csv'))\n",
    "        \n",
    "    # Write out the dataframe to a .csv file:\n",
    "    output_df.to_csv(csv_output_filename, sep=',', index=False)\n",
    "    \n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e41ca9-a081-4ffb-92d2-045c965423a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_df = process_ba_time_series(ba_to_process = 'ERCO', \n",
    "                                   start_year = 1980, \n",
    "                                   end_year = 1990, \n",
    "                                   weather_data_dir = weather_data_dir, \n",
    "                                   service_territory_data_dir = service_territory_data_dir, \n",
    "                                   population_data_dir = population_data_dir, \n",
    "                                   load_data_dir = load_data_dir, \n",
    "                                   data_output_dir = data_output_dir)\n",
    "\n",
    "output_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b01e46-059f-4ee1-b268-e8fff0034631",
   "metadata": {},
   "source": [
    "## Make the Time Series and Error Distribution Plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ad948-f11d-4ff7-a2af-6f17baf6e187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.15_std",
   "language": "python",
   "name": "py3.9.15_std"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
