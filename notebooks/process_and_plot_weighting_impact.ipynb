{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd40f4f4-5a80-40b7-94b3-aed136daa9d8",
   "metadata": {},
   "source": [
    "# Evaluate the Impact of Population-Weighting on Heat Wave Events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27e597e9-538f-41d4-afa9-a268b10ab1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing the packages we need:\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f6fe5-0769-4298-887e-7c4cffc64a0d",
   "metadata": {},
   "source": [
    "## Set the Directory Structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd887600-32da-46dc-b411-fa63c75f564f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the data input and image output directories:\n",
    "service_territory_data_dir = '/Users/burl878/Documents/IMMM/Data/TELL/Production_Runs/tell_data/ba_service_territory_data/'\n",
    "population_data_dir = '/Users/burl878/Documents/IMMM/Data/TELL/Production_Runs/tell_data/population_data/'\n",
    "weather_data_dir =  '/Users/burl878/Documents/IMMM/Data/TELL/Production_Runs/tell_data/wrf_tell_counties_output/historic/'\n",
    "load_data_dir = '/Users/burl878/Documents/IMMM/Data/TELL/Production_Runs/tell_data/outputs/mlp_output/historic/'\n",
    "data_output_dir =  '/Users/burl878/Documents/Code/code_repos/nerc_analysis/data/'\n",
    "image_output_dir =  '/Users/burl878/Documents/Code/code_repos/nerc_analysis/plots/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7a320d-804a-44c4-b415-da9450d37344",
   "metadata": {},
   "source": [
    "## Process the Weather and Load Time Series by BA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77098b53-9385-4a75-92af-f106f7715804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to process the load time series for a given BA and date range:\n",
    "def process_ba_load_time_series(ba_to_process: str, start_year: int, end_year: int, load_data_dir: str):\n",
    "    \n",
    "    # Loop over the years of load data:\n",
    "    for year in range(start_year, end_year, 1):\n",
    "        \n",
    "        # Read in the .csv file and replace missing values with nan:\n",
    "        mlp_data = pd.read_csv((load_data_dir + '/' + str(year) + '/' + ba_to_process + '_' + str(year) + '_mlp_output.csv')).replace(-9999, np.nan)\n",
    "\n",
    "        # Set the time variable as a datetime variable:\n",
    "        mlp_data['Time_UTC'] = pd.to_datetime(mlp_data['Time_UTC'])\n",
    "        \n",
    "        # Rename the \"BA\" variable:\n",
    "        mlp_data.rename(columns={'BA': 'BA_Code'}, inplace=True)\n",
    "\n",
    "        # Rename the \"Load\" variable:\n",
    "        mlp_data.rename(columns={'Load': 'Load_MWh'}, inplace=True)\n",
    "\n",
    "        # Replacing missing or negative loads with NaN:\n",
    "        mlp_data.loc[~(mlp_data['Load_MWh'] > 0), 'Load_MWh'] = np.nan\n",
    "\n",
    "        # Subset to just the variables we need:\n",
    "        mlp_data = mlp_data[['Time_UTC', 'Load_MWh']]\n",
    "    \n",
    "        # Aggregate the output into a new dataframe:\n",
    "        if year == start_year:\n",
    "           mlp_output_df = mlp_data\n",
    "        else:\n",
    "           mlp_output_df = pd.concat([mlp_output_df, mlp_data])\n",
    "        \n",
    "    return mlp_output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56f141a5-13fe-436e-a241-1a7dd3808314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process the time series for a given BA and date range:\n",
    "def process_ba_time_series(ba_to_process: str, start_year: int, end_year: int, weather_data_dir: str, service_territory_data_dir: str, \n",
    "                           population_data_dir: str, load_data_dir: str, data_output_dir: str):\n",
    "    \n",
    "    # Read in the county-level population data:\n",
    "    pop_df = pd.read_csv(population_data_dir + 'county_populations_2000_to_2020.csv')\n",
    "\n",
    "    # Subset to just the variables we need:\n",
    "    pop_df = pop_df[['county_FIPS', 'pop_2019']]\n",
    "\n",
    "    # Rename the variables for simplicity:\n",
    "    pop_df.rename(columns={'county_FIPS': 'FIPS', 'pop_2019': 'Population'}, inplace=True)\n",
    "    \n",
    "    # Read in the BA-to-county mapping file:\n",
    "    mapping_df = pd.read_csv(service_territory_data_dir + 'ba_service_territory_2019.csv')\n",
    "    \n",
    "    # Subset to just the BA you want to process:\n",
    "    mapping_df = mapping_df.loc[(mapping_df['BA_Code'] == ba_to_process)]\n",
    "    \n",
    "    # Rename the variables for simplicity:\n",
    "    mapping_df.rename(columns={'County_FIPS': 'FIPS'}, inplace=True)\n",
    "    \n",
    "    # Subset to just the variables we need:\n",
    "    mapping_df = mapping_df[['BA_Code', 'FIPS']]\n",
    "    \n",
    "    # Initiate a counter to store the results:\n",
    "    counter = 0;\n",
    "    output_df = pd.DataFrame()\n",
    "    \n",
    "    # Loop over the years of weather data:\n",
    "    for year in range(start_year, end_year, 1):\n",
    "        \n",
    "        # Print the year\n",
    "        print(str(year))\n",
    "        \n",
    "        # Create a list of all county meteorology files in the input directory:\n",
    "        list_of_files = glob(os.path.join(weather_data_dir, str(year), '*.csv'))\n",
    "    \n",
    "        # Loop over that list process each file:\n",
    "        for file in range(len(list_of_files)):\n",
    "        # for file in range(1):\n",
    "            # Iterate the counter by one:\n",
    "            counter = counter + 1\n",
    "        \n",
    "            # Extract the filename from the list:\n",
    "            filename = list_of_files[file].rsplit('/', 1)[1]\n",
    "       \n",
    "            # Extract the time string from the name of the file:\n",
    "            filetime = filename.replace(\"_UTC_County_Mean_Meteorology.csv\", \"\")\n",
    "            \n",
    "            # Read in the .csv file:\n",
    "            met_df = pd.read_csv(list_of_files[file])\n",
    "            \n",
    "            # Convert the temperature from Kelvin to Fahrenheit:\n",
    "            met_df['T2'] = (1.8 * (met_df['T2'] - 273)) + 32\n",
    "        \n",
    "            # Merge the meteorology and population data into the mapping_df\n",
    "            ba_df = mapping_df.merge(met_df, on=['FIPS']).merge(pop_df, on=['FIPS'])\n",
    "        \n",
    "            # Compute the fraction of the total population in the BA that lives in a given county:\n",
    "            ba_df['Population_Fraction'] = ba_df['Population'] / (ba_df['Population'].sum())\n",
    "\n",
    "            # Population-weight T2:\n",
    "            ba_df['T2_Weighted'] = (ba_df['T2'].mul(ba_df['Population_Fraction']))\n",
    "       \n",
    "            # Add the time step to the output file:\n",
    "            output_df.loc[counter, 'Time_UTC'] = pd.to_datetime(filetime, exact=False, format='%Y_%m_%d_%H')\n",
    "            output_df.loc[counter, 'T2_UW'] = (ba_df['T2'].mean()).round(2)\n",
    "            output_df.loc[counter, 'T2_PW'] = (ba_df['T2_Weighted'].sum()).round(2)\n",
    "            output_df.loc[counter, 'T2_Min'] = ba_df['T2'].min().round(2)\n",
    "            output_df.loc[counter, 'T2_Max'] = ba_df['T2'].max().round(2)\n",
    "            \n",
    "            # Clean up the old dataframes and move to the next file in the loop:\n",
    "            del filename, filetime, met_df, ba_df\n",
    "        \n",
    "    # Sort by time:\n",
    "    output_df = output_df.sort_values(['Time_UTC'])\n",
    "    \n",
    "    # Aggregate the TELL MLP output for the BA and date range:\n",
    "    load_df = process_ba_load_time_series(ba_to_process = ba_to_process, \n",
    "                                          start_year = start_year, \n",
    "                                          end_year = end_year, \n",
    "                                          load_data_dir = load_data_dir)\n",
    "    \n",
    "    # Merge the meteorology and load data:\n",
    "    output_df = output_df.merge(load_df, on=['Time_UTC'])\n",
    "        \n",
    "    # Create the ouput filename:    \n",
    "    csv_output_filename = os.path.join(data_output_dir, (ba_to_process + '_Time_Series_' + str(start_year) + '_to_' + str(end_year) + '.csv'))\n",
    "        \n",
    "    # Write out the dataframe to a .csv file:\n",
    "    output_df.to_csv(csv_output_filename, sep=',', index=False)\n",
    "    \n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e41ca9-a081-4ffb-92d2-045c965423a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_df = process_ba_time_series(ba_to_process = 'CISO', \n",
    "                                   start_year = 1980, \n",
    "                                   end_year = 2020, \n",
    "                                   weather_data_dir = weather_data_dir, \n",
    "                                   service_territory_data_dir = service_territory_data_dir, \n",
    "                                   population_data_dir = population_data_dir, \n",
    "                                   load_data_dir = load_data_dir, \n",
    "                                   data_output_dir = data_output_dir)\n",
    "\n",
    "output_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04fca80-914f-47d2-b041-8b1fa5d9029c",
   "metadata": {},
   "source": [
    "## Classify Heat Wave Events Based on Historical Temperatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "fe483188-99e4-4757-8a16-465e93c9a801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to classify heat wave events based on one criteria:\n",
    "#  1) Daily maximum temperature exceeds the 95th percentile of temperature from a given range of base years for two or more days\n",
    "\n",
    "def process_heat_wave_time_series(ba_to_process: str, start_year: int, end_year: int, base_year_start: int, base_year_end: int,\n",
    "                                  weather_data_dir: str, service_territory_data_dir: str, \n",
    "                                  population_data_dir: str, load_data_dir: str, data_output_dir: str):\n",
    "    \n",
    "    # Check to see if the output already exist and if not then process it:\n",
    "    if os.path.isfile(os.path.join(data_output_dir, (ba_to_process + '_Time_Series_' + str(start_year) + '_to_' + str(end_year) + '.csv'))) == True:\n",
    "       # Load in the pre-processed data:\n",
    "       met_df = pd.read_csv(os.path.join(data_output_dir, (ba_to_process + '_Time_Series_' + str(start_year) + '_to_' + str(end_year) + '.csv')))\n",
    "    else:\n",
    "       met_df = process_ba_time_series(ba_to_process = ba_to_process, \n",
    "                                       start_year = start_year, \n",
    "                                       end_year = end_year, \n",
    "                                       weather_data_dir = weather_data_dir, \n",
    "                                       service_territory_data_dir = service_territory_data_dir, \n",
    "                                       population_data_dir = population_data_dir, \n",
    "                                       load_data_dir = load_data_dir, \n",
    "                                       data_output_dir = data_output_dir)\n",
    "    \n",
    "    # Make a copy of the dataframe for later:\n",
    "    output_df = met_df.copy()\n",
    "    \n",
    "    # Set the time variable as an index:\n",
    "    met_df.index = pd.to_datetime(met_df['Time_UTC'])\n",
    "        \n",
    "    # Compute the daily minimum and maximum temperature using resampling:\n",
    "    uw_df = met_df.resample('D')['T2_UW'].agg(['min', 'max']).reset_index()\n",
    "    pw_df = met_df.resample('D')['T2_PW'].agg(['min', 'max']).reset_index()\n",
    "        \n",
    "    # Rename the variables for consistency:\n",
    "    uw_df.rename(columns={'Time_UTC': 'Day', 'min': 'T2_UW_Min', 'max': 'T2_UW_Max'}, inplace=True)      \n",
    "    pw_df.rename(columns={'Time_UTC': 'Day', 'min': 'T2_PW_Min', 'max': 'T2_PW_Max'}, inplace=True)      \n",
    "   \n",
    "    # Merge the two dataframes together based on common days:\n",
    "    daily_df = uw_df.merge(pw_df, on=['Day'])\n",
    "    \n",
    "    # Add a column with the year values to be used in grouping:\n",
    "    daily_df['Year'] = daily_df['Day'].dt.year\n",
    "        \n",
    "    # Subset the daily data to just the base year to calculate extreme temperature thresholds:\n",
    "    daily_df_subset = daily_df.loc[(daily_df['Year'] >= base_year_start) & (daily_df['Year'] <= base_year_end)]\n",
    "    \n",
    "    # Calculate the temperature thresholds based on the 95th percentile of historical daily maximum temperature:\n",
    "    uw_t_threshold = daily_df_subset['T2_UW_Max'].quantile(0.95).round(2)\n",
    "    pw_t_threshold = daily_df_subset['T2_PW_Max'].quantile(0.95).round(2)\n",
    "    \n",
    "    # Print the values:\n",
    "    print(('Unweighted Temperature Threshold = ' + str(uw_t_threshold) + 'F'))\n",
    "    print(('Population-Weighted Temperature Threshold = ' + str(pw_t_threshold) + 'F'))\n",
    "    \n",
    "    # Create some heat wave index variables:\n",
    "    daily_df['UW_Heat_Wave_Initial'] = 0\n",
    "    daily_df['PW_Heat_Wave_Initial'] = 0\n",
    "    daily_df['UW_Heat_Wave_Final'] = 0\n",
    "    daily_df['PW_Heat_Wave_Final'] = 0\n",
    "    daily_df['Joint_Heat_Wave_Final'] = 0\n",
    "    \n",
    "    # Mark the heat waves based on days that exceed the temperature threshold:\n",
    "    daily_df.loc[daily_df['T2_UW_Max'] >= uw_t_threshold, 'UW_Heat_Wave_Initial'] = 1\n",
    "    daily_df.loc[daily_df['T2_PW_Max'] >= pw_t_threshold, 'PW_Heat_Wave_Initial'] = 1\n",
    "    \n",
    "    # Loop through the dataframe and check to see if consecutive days exceed the temperature threshold:\n",
    "    #daily_df['Test'] = (daily_df['UW_Heat_Wave_Initial'].diff(1)).astype('int')\n",
    "    for row in range(1,(len(daily_df)-1)):\n",
    "        if (((daily_df.loc[row, 'UW_Heat_Wave_Initial'] == 1) and (daily_df.loc[(row+1), 'UW_Heat_Wave_Initial'] == 1)) | \n",
    "            ((daily_df.loc[row, 'UW_Heat_Wave_Initial'] == 1) and (daily_df.loc[(row-1), 'UW_Heat_Wave_Initial'] == 1))):\n",
    "           daily_df.loc[row, 'UW_Heat_Wave_Final'] = 1\n",
    "        if (((daily_df.loc[row, 'PW_Heat_Wave_Initial'] == 1) and (daily_df.loc[(row+1), 'PW_Heat_Wave_Initial'] == 1)) | \n",
    "            ((daily_df.loc[row, 'PW_Heat_Wave_Initial'] == 1) and (daily_df.loc[(row-1), 'PW_Heat_Wave_Initial'] == 1))):\n",
    "           daily_df.loc[row, 'PW_Heat_Wave_Final'] = 1\n",
    "        if (daily_df.loc[row, 'UW_Heat_Wave_Final'] == 1) and (daily_df.loc[row, 'PW_Heat_Wave_Final'] == 1):\n",
    "           daily_df.loc[row, 'Joint_Heat_Wave_Final'] = 1\n",
    "    \n",
    "    # Rename the variables for simplicity:\n",
    "    daily_df.rename(columns={'UW_Heat_Wave_Final': 'UW_HW', 'PW_Heat_Wave_Final': 'PW_HW', 'Joint_Heat_Wave_Final': 'Joint_HW'}, inplace=True)\n",
    "    \n",
    "    # Subset to just the variables we need:\n",
    "    daily_df = daily_df[['Day', 'UW_HW', 'PW_HW', 'Joint_HW']]\n",
    "    \n",
    "    # Set the time variable as a datetime variable:\n",
    "    daily_df['Date'] = pd.to_datetime(daily_df['Day'])\n",
    "    daily_df['Day'] = daily_df['Date'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Set the time variable as an index:\n",
    "    output_df['Time_UTC'] = pd.to_datetime(output_df['Time_UTC'])\n",
    "    \n",
    "    # Reset the index:\n",
    "    output_df.reset_index()\n",
    "    \n",
    "    # Add a column with the day values to be used in grouping:\n",
    "    output_df['Day'] = output_df['Time_UTC'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Merge the two dataframes together based on common days:\n",
    "    output_df = output_df.merge(daily_df, on=['Day'])\n",
    "    \n",
    "    # Subset to just the variables we need:\n",
    "    output_df = output_df[['Time_UTC', 'T2_UW', 'T2_PW', 'T2_Min', 'T2_Max', 'Load_MWh', 'UW_HW', 'PW_HW', 'Joint_HW']]\n",
    "    \n",
    "    # Create the ouput filename:    \n",
    "    csv_output_filename = os.path.join(data_output_dir, (ba_to_process + '_Heat_Wave_Time_Series_' + str(start_year) + '_to_' + str(end_year) + '.csv'))\n",
    "        \n",
    "    # Write out the dataframe to a .csv file:\n",
    "    output_df.to_csv(csv_output_filename, sep=',', index=False)\n",
    "    \n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0e4bb2b2-ad20-4f37-b3e2-f387712f0d35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted Temperature Threshold = 89.54F\n",
      "Population-Weighted Temperature Threshold = 89.48F\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_UTC</th>\n",
       "      <th>T2_UW</th>\n",
       "      <th>T2_PW</th>\n",
       "      <th>T2_Min</th>\n",
       "      <th>T2_Max</th>\n",
       "      <th>Load_MWh</th>\n",
       "      <th>UW_HW</th>\n",
       "      <th>PW_HW</th>\n",
       "      <th>Joint_HW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-01 00:00:00</td>\n",
       "      <td>51.76</td>\n",
       "      <td>57.85</td>\n",
       "      <td>33.57</td>\n",
       "      <td>65.79</td>\n",
       "      <td>24458.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-01-01 01:00:00</td>\n",
       "      <td>50.35</td>\n",
       "      <td>55.59</td>\n",
       "      <td>32.47</td>\n",
       "      <td>61.54</td>\n",
       "      <td>25630.37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-01-01 02:00:00</td>\n",
       "      <td>49.78</td>\n",
       "      <td>54.45</td>\n",
       "      <td>31.62</td>\n",
       "      <td>59.29</td>\n",
       "      <td>26350.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-01-01 03:00:00</td>\n",
       "      <td>49.29</td>\n",
       "      <td>53.73</td>\n",
       "      <td>30.56</td>\n",
       "      <td>58.42</td>\n",
       "      <td>27341.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-01-01 04:00:00</td>\n",
       "      <td>48.90</td>\n",
       "      <td>53.27</td>\n",
       "      <td>29.80</td>\n",
       "      <td>57.88</td>\n",
       "      <td>27805.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350635</th>\n",
       "      <td>2019-12-31 19:00:00</td>\n",
       "      <td>50.79</td>\n",
       "      <td>54.34</td>\n",
       "      <td>31.50</td>\n",
       "      <td>64.56</td>\n",
       "      <td>24445.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350636</th>\n",
       "      <td>2019-12-31 20:00:00</td>\n",
       "      <td>52.32</td>\n",
       "      <td>55.82</td>\n",
       "      <td>32.81</td>\n",
       "      <td>66.00</td>\n",
       "      <td>24391.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350637</th>\n",
       "      <td>2019-12-31 21:00:00</td>\n",
       "      <td>53.26</td>\n",
       "      <td>56.58</td>\n",
       "      <td>33.48</td>\n",
       "      <td>66.63</td>\n",
       "      <td>24449.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350638</th>\n",
       "      <td>2019-12-31 22:00:00</td>\n",
       "      <td>53.54</td>\n",
       "      <td>56.72</td>\n",
       "      <td>33.75</td>\n",
       "      <td>66.45</td>\n",
       "      <td>24723.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350639</th>\n",
       "      <td>2019-12-31 23:00:00</td>\n",
       "      <td>52.97</td>\n",
       "      <td>56.02</td>\n",
       "      <td>32.72</td>\n",
       "      <td>65.12</td>\n",
       "      <td>25248.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350640 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Time_UTC  T2_UW  T2_PW  T2_Min  T2_Max  Load_MWh  UW_HW  \\\n",
       "0      1980-01-01 00:00:00  51.76  57.85   33.57   65.79  24458.49      0   \n",
       "1      1980-01-01 01:00:00  50.35  55.59   32.47   61.54  25630.37      0   \n",
       "2      1980-01-01 02:00:00  49.78  54.45   31.62   59.29  26350.95      0   \n",
       "3      1980-01-01 03:00:00  49.29  53.73   30.56   58.42  27341.88      0   \n",
       "4      1980-01-01 04:00:00  48.90  53.27   29.80   57.88  27805.27      0   \n",
       "...                    ...    ...    ...     ...     ...       ...    ...   \n",
       "350635 2019-12-31 19:00:00  50.79  54.34   31.50   64.56  24445.51      0   \n",
       "350636 2019-12-31 20:00:00  52.32  55.82   32.81   66.00  24391.69      0   \n",
       "350637 2019-12-31 21:00:00  53.26  56.58   33.48   66.63  24449.65      0   \n",
       "350638 2019-12-31 22:00:00  53.54  56.72   33.75   66.45  24723.10      0   \n",
       "350639 2019-12-31 23:00:00  52.97  56.02   32.72   65.12  25248.45      0   \n",
       "\n",
       "        PW_HW  Joint_HW  \n",
       "0           0         0  \n",
       "1           0         0  \n",
       "2           0         0  \n",
       "3           0         0  \n",
       "4           0         0  \n",
       "...       ...       ...  \n",
       "350635      0         0  \n",
       "350636      0         0  \n",
       "350637      0         0  \n",
       "350638      0         0  \n",
       "350639      0         0  \n",
       "\n",
       "[350640 rows x 9 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = process_heat_wave_time_series(ba_to_process = 'CISO', \n",
    "                                          start_year = 1980, \n",
    "                                          end_year = 2020, \n",
    "                                          base_year_start = 1980,\n",
    "                                          base_year_end = 1990,\n",
    "                                          weather_data_dir = weather_data_dir, \n",
    "                                          service_territory_data_dir = service_territory_data_dir, \n",
    "                                          population_data_dir = population_data_dir, \n",
    "                                          load_data_dir = load_data_dir, \n",
    "                                          data_output_dir = data_output_dir)\n",
    "\n",
    "output_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b01e46-059f-4ee1-b268-e8fff0034631",
   "metadata": {},
   "source": [
    "## Make the Plots to Characterize the Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "859ad948-f11d-4ff7-a2af-6f17baf6e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heat_wave_frequency(ba_to_process: str, start_year: int, end_year: int, base_year_start: int, base_year_end: int,\n",
    "                             weather_data_dir: str, service_territory_data_dir: str, \n",
    "                             population_data_dir: str, load_data_dir: str, data_output_dir: str,\n",
    "                             image_output_dir: str, image_resolution: int, save_images=False):\n",
    "    \n",
    "    # Check to see if the output already exist and if not then process it:\n",
    "    if os.path.isfile(os.path.join(data_output_dir, (ba_to_process + '_Heat_Wave_Time_Series_' + str(start_year) + '_to_' + str(end_year) + '.csv'))) == True:\n",
    "       # Load in the pre-processed data:\n",
    "       met_df = pd.read_csv(os.path.join(data_output_dir, (ba_to_process + '_Heat_Wave_Time_Series_' + str(start_year) + '_to_' + str(end_year) + '.csv')))\n",
    "    else:\n",
    "       met_df = process_heat_wave_time_series(ba_to_process = ba_to_process, \n",
    "                                              start_year = start_year, \n",
    "                                              end_year = end_year, \n",
    "                                              base_year_start = base_year_start,\n",
    "                                              base_year_end = base_year_end,\n",
    "                                              weather_data_dir = weather_data_dir, \n",
    "                                              service_territory_data_dir = service_territory_data_dir, \n",
    "                                              population_data_dir = population_data_dir, \n",
    "                                              load_data_dir = load_data_dir, \n",
    "                                              data_output_dir = data_output_dir)\n",
    "    \n",
    "    # Set the time variable as an index:\n",
    "    met_df.index = pd.to_datetime(met_df['Time_UTC'])\n",
    "    \n",
    "    # Compute the daily minimum and maximum temperature using resampling:\n",
    "    uw_df = met_df.resample('D')['T2_UW'].agg(['min', 'max']).reset_index()\n",
    "    pw_df = met_df.resample('D')['T2_PW'].agg(['min', 'max']).reset_index()\n",
    "    uw_hw_df = met_df.resample('D')['UW_HW'].agg(['max']).reset_index()\n",
    "    pw_hw_df = met_df.resample('D')['PW_HW'].agg(['max']).reset_index()\n",
    "    joint_hw_df = met_df.resample('D')['Joint_HW'].agg(['max']).reset_index()\n",
    "        \n",
    "    # Rename the variables for consistency:\n",
    "    uw_df.rename(columns={'Time_UTC': 'Day', 'min': 'T2_UW_Min', 'max': 'T2_UW_Max'}, inplace=True)      \n",
    "    pw_df.rename(columns={'Time_UTC': 'Day', 'min': 'T2_PW_Min', 'max': 'T2_PW_Max'}, inplace=True)      \n",
    "    uw_hw_df.rename(columns={'Time_UTC': 'Day', 'max': 'UW_HW'}, inplace=True)  \n",
    "    pw_hw_df.rename(columns={'Time_UTC': 'Day', 'max': 'PW_HW'}, inplace=True)\n",
    "    joint_hw_df.rename(columns={'Time_UTC': 'Day', 'max': 'Joint_HW'}, inplace=True) \n",
    "   \n",
    "    # Merge the two dataframes together based on common days:\n",
    "    daily_df = uw_df.merge(pw_df, on=['Day']).merge(uw_hw_df, on=['Day']).merge(pw_hw_df, on=['Day']).merge(joint_hw_df, on=['Day'])\n",
    "    \n",
    "    # Calculate the number of heat wave days:\n",
    "    uw_hw_count = (len(daily_df.loc[daily_df['UW_HW'] == 1]))/40\n",
    "    pw_hw_count = (len(daily_df.loc[daily_df['PW_HW'] == 1]))/40\n",
    "    \n",
    "    print('Unweighted Heat Wave Days Per Year = ' + str(uw_hw_count))\n",
    "    print('Population-Weighted Heat Wave Days Per Year = ' + str(pw_hw_count))\n",
    "    \n",
    "    # Make the plot:\n",
    "    fig, ax = plt.subplots(2, figsize=(25, 15), sharex=True, sharey=True)\n",
    "    plt.rcParams['font.size'] = 18\n",
    "    ax[0].plot(daily_df['Day'], 200*daily_df['UW_HW'], 'r-', label=('Unweighted Heat Waves: N = ' + str(uw_hw_count) + ' Per Year'), linewidth=1)\n",
    "    ax[0].plot(daily_df['Day'], daily_df['T2_UW_Max'], 'k-', label='Unweighted T2 Max', linewidth=1)\n",
    "    ax[1].plot(daily_df['Day'], 200*daily_df['PW_HW'], 'r-', label=('Pop-Weighted Heat Waves: N = ' + str(pw_hw_count) + ' Per Year'), linewidth=1)\n",
    "    ax[1].plot(daily_df['Day'], daily_df['T2_PW_Max'], 'k-', label='Pop-Weighted T2 Max', linewidth=1)\n",
    "    plt.xlim(daily_df['Day'].min(), daily_df['Day'].max())\n",
    "    plt.ylim(daily_df[['T2_UW_Max', 'T2_PW_Max']].min().min(), daily_df[['T2_UW_Max', 'T2_PW_Max']].max().max())\n",
    "    ax[0].set_title((ba_to_process + ' Unweighted Daily Maximum Temperature: ' + str(start_year) + ' to ' + str(end_year)))\n",
    "    ax[1].set_title((ba_to_process + ' Population-Weighted Daily Maximum Temperature: ' + str(start_year) + ' to ' + str(end_year)))\n",
    "    ax[0].set_ylabel('Daily Maximum Temperature [$^\\circ$F]')\n",
    "    ax[1].set_ylabel('Daily Maximum Temperature [$^\\circ$F]')\n",
    "    ax[0].legend(loc='lower right', facecolor='white', framealpha=1)\n",
    "    ax[1].legend(loc='lower right', facecolor='white', framealpha=1)\n",
    "    \n",
    "    # If the \"save_images\" flag is set to true then save the plot to a .png file:\n",
    "    if save_images == True:\n",
    "       plt.savefig(os.path.join(image_output_dir, (ba_to_process + '_Heat_Wave_Time_Series_' + str(start_year) + '_to_' + str(end_year) + '.png')), \n",
    "                   dpi=image_resolution, bbox_inches='tight', facecolor='white')\n",
    "       plt.close()\n",
    "    \n",
    "    # Make a copy of the dataframe in order to add random noise:\n",
    "    noise_daily_df = daily_df.copy()\n",
    "    \n",
    "    # Add in random noise around the heat wave points:\n",
    "    noise_daily_df['UW_HW_Noise'] = noise_daily_df['UW_HW'] + np.random.normal(0, 0.05, [len(noise_daily_df)])\n",
    "    noise_daily_df['PW_HW_Noise'] = noise_daily_df['PW_HW'] + np.random.normal(0, 0.05, [len(noise_daily_df)])\n",
    "    \n",
    "    # Calculate the heat wave detection statistics:\n",
    "    no_no = noise_daily_df.loc[(noise_daily_df['UW_HW'] == 0) & (noise_daily_df['PW_HW'] == 0)]\n",
    "    yes_no = noise_daily_df.loc[(noise_daily_df['UW_HW'] == 1) & (noise_daily_df['PW_HW'] == 0)]\n",
    "    no_yes = noise_daily_df.loc[(daily_df['UW_HW'] == 0) & (noise_daily_df['PW_HW'] == 1)]\n",
    "    yes_yes = noise_daily_df.loc[(daily_df['UW_HW'] == 1) & (noise_daily_df['PW_HW'] == 1)]\n",
    "    \n",
    "    # Make the plot:\n",
    "    plt.figure(figsize=(25, 15))\n",
    "    plt.rcParams['font.size'] = 18\n",
    "    plt.scatter(no_no['UW_HW_Noise'], no_no['PW_HW_Noise'], s=15, c='black', label=('No Unweighted HW, No Pop-Weighted HW, N = ' + str(len(no_no)) + ' Days'))\n",
    "    plt.scatter(yes_no['UW_HW_Noise'], yes_no['PW_HW_Noise'], s=15, c='green', label=('Unweighted HW, No Pop-Weighted HW, N = ' + str(len(yes_no)) + ' Days'))\n",
    "    plt.scatter(no_yes['UW_HW_Noise'], no_yes['PW_HW_Noise'], s=15, c='blue', label=('No Unweighted HW, Pop-Weighted HW, N = ' + str(len(no_yes)) + ' Days'))\n",
    "    plt.scatter(yes_yes['UW_HW_Noise'], yes_yes['PW_HW_Noise'], s=15, c='red', label=('Unweighted HW, Pop-Weighted HW, N = ' + str(len(yes_yes)) + ' Days'))\n",
    "    plt.grid()\n",
    "    plt.xlim(-0.25, 1.25)\n",
    "    plt.ylim(-0.25, 1.25)\n",
    "    plt.xlabel('Unweighted Heat Wave Detected: 0 = No, 1 = Yes')\n",
    "    plt.ylabel('Population-Weighted Heat Wave Detected: 0 = No, 1 = Yes')\n",
    "    plt.legend(loc='center', facecolor='white', framealpha=1)\n",
    "    plt.title('Heat Wave Detection Frequency in ' + ba_to_process + ' from ' + str(start_year) + ' to ' + str(end_year))\n",
    "    \n",
    "    # If the \"save_images\" flag is set to true then save the plot to a .png file:\n",
    "    if save_images == True:\n",
    "       plt.savefig(os.path.join(image_output_dir, (ba_to_process + '_Heat_Wave_Detection_' + str(start_year) + '_to_' + str(end_year) + '.png')), \n",
    "                   dpi=image_resolution, bbox_inches='tight', facecolor='white')\n",
    "       plt.close()\n",
    "    \n",
    "    return daily_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e754e920-6489-41cd-9170-00bd9dce9ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted Heat Wave Days Per Year = 23.6\n",
      "Population-Weighted Heat Wave Days Per Year = 22.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>T2_UW_Min</th>\n",
       "      <th>T2_UW_Max</th>\n",
       "      <th>T2_PW_Min</th>\n",
       "      <th>T2_PW_Max</th>\n",
       "      <th>UW_HW</th>\n",
       "      <th>PW_HW</th>\n",
       "      <th>Joint_HW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>34.28</td>\n",
       "      <td>58.79</td>\n",
       "      <td>32.41</td>\n",
       "      <td>57.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-01-02</td>\n",
       "      <td>39.54</td>\n",
       "      <td>60.55</td>\n",
       "      <td>36.58</td>\n",
       "      <td>61.59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-01-03</td>\n",
       "      <td>42.65</td>\n",
       "      <td>54.94</td>\n",
       "      <td>47.18</td>\n",
       "      <td>56.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-01-04</td>\n",
       "      <td>32.65</td>\n",
       "      <td>53.25</td>\n",
       "      <td>32.07</td>\n",
       "      <td>51.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-01-05</td>\n",
       "      <td>34.18</td>\n",
       "      <td>56.45</td>\n",
       "      <td>32.52</td>\n",
       "      <td>55.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14605</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>52.88</td>\n",
       "      <td>64.19</td>\n",
       "      <td>54.25</td>\n",
       "      <td>68.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14606</th>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>57.10</td>\n",
       "      <td>66.42</td>\n",
       "      <td>57.89</td>\n",
       "      <td>70.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14607</th>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>45.89</td>\n",
       "      <td>60.87</td>\n",
       "      <td>50.71</td>\n",
       "      <td>64.48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14608</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>34.04</td>\n",
       "      <td>54.29</td>\n",
       "      <td>33.72</td>\n",
       "      <td>56.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14609</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>34.76</td>\n",
       "      <td>55.25</td>\n",
       "      <td>33.59</td>\n",
       "      <td>57.08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14610 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Day  T2_UW_Min  T2_UW_Max  T2_PW_Min  T2_PW_Max  UW_HW  PW_HW  \\\n",
       "0     1980-01-01      34.28      58.79      32.41      57.63      0      0   \n",
       "1     1980-01-02      39.54      60.55      36.58      61.59      0      0   \n",
       "2     1980-01-03      42.65      54.94      47.18      56.56      0      0   \n",
       "3     1980-01-04      32.65      53.25      32.07      51.44      0      0   \n",
       "4     1980-01-05      34.18      56.45      32.52      55.97      0      0   \n",
       "...          ...        ...        ...        ...        ...    ...    ...   \n",
       "14605 2019-12-27      52.88      64.19      54.25      68.41      0      0   \n",
       "14606 2019-12-28      57.10      66.42      57.89      70.01      0      0   \n",
       "14607 2019-12-29      45.89      60.87      50.71      64.48      0      0   \n",
       "14608 2019-12-30      34.04      54.29      33.72      56.75      0      0   \n",
       "14609 2019-12-31      34.76      55.25      33.59      57.08      0      0   \n",
       "\n",
       "       Joint_HW  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "14605         0  \n",
       "14606         0  \n",
       "14607         0  \n",
       "14608         0  \n",
       "14609         0  \n",
       "\n",
       "[14610 rows x 8 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = plot_heat_wave_frequency(ba_to_process = 'ERCO', \n",
    "                                     start_year = 1980, \n",
    "                                     end_year = 2020, \n",
    "                                     base_year_start = 1980,\n",
    "                                     base_year_end = 1990,\n",
    "                                     weather_data_dir = weather_data_dir, \n",
    "                                     service_territory_data_dir = service_territory_data_dir, \n",
    "                                     population_data_dir = population_data_dir, \n",
    "                                     load_data_dir = load_data_dir, \n",
    "                                     data_output_dir = data_output_dir,\n",
    "                                     image_output_dir = image_output_dir, \n",
    "                                     image_resolution = 300, \n",
    "                                     save_images = True)\n",
    "\n",
    "output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "78ca8c9a-5069-40d7-a2d3-4f3f6f00e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heat_wave_characteristics(ba_to_process: str, start_year: int, end_year: int, base_year_start: int, base_year_end: int,\n",
    "                                   weather_data_dir: str, service_territory_data_dir: str, \n",
    "                                   population_data_dir: str, load_data_dir: str, data_output_dir: str,\n",
    "                                   image_output_dir: str, image_resolution: int, save_images=False):\n",
    "    \n",
    "    # Check to see if the output already exist and if not then process it:\n",
    "    if os.path.isfile(os.path.join(data_output_dir, (ba_to_process + '_Heat_Wave_Time_Series_' + str(start_year) + '_to_' + str(end_year) + '.csv'))) == True:\n",
    "       # Load in the pre-processed data:\n",
    "       met_df = pd.read_csv(os.path.join(data_output_dir, (ba_to_process + '_Heat_Wave_Time_Series_' + str(start_year) + '_to_' + str(end_year) + '.csv')))\n",
    "    else:\n",
    "       met_df = process_heat_wave_time_series(ba_to_process = ba_to_process, \n",
    "                                              start_year = start_year, \n",
    "                                              end_year = end_year, \n",
    "                                              base_year_start = base_year_start,\n",
    "                                              base_year_end = base_year_end,\n",
    "                                              weather_data_dir = weather_data_dir, \n",
    "                                              service_territory_data_dir = service_territory_data_dir, \n",
    "                                              population_data_dir = population_data_dir, \n",
    "                                              load_data_dir = load_data_dir, \n",
    "                                              data_output_dir = data_output_dir)\n",
    "    \n",
    "    # Subset to just the heat wave days:\n",
    "    uw_hw = met_df.loc[(met_df['UW_HW'] == 1)]\n",
    "    pw_hw = met_df.loc[(met_df['PW_HW'] == 1)]\n",
    "    \n",
    "    # Make the plot:\n",
    "    plt.figure(figsize=(25, 15))\n",
    "    plt.rcParams['font.size'] = 18\n",
    "    plt.subplot(221)\n",
    "    plt.hist(uw_hw['T2_UW'], bins=25, density=True, histtype='step', edgecolor = 'r', label=('Mean=' + str(uw_hw['T2_UW'].mean().round(1)) + '$^\\circ$F, Max=' + str(uw_hw['T2_UW'].max().round(1)) + '$^\\circ$F'), linewidth=3)\n",
    "    plt.legend(loc='upper center', facecolor='white', framealpha=1)\n",
    "    plt.title('Unweighted HW Temperatures in ' + ba_to_process)\n",
    "    \n",
    "    plt.subplot(222)\n",
    "    plt.hist(uw_hw['Load_MWh'], bins=25, density=True, histtype='step', edgecolor = 'b', label=('Mean=' + str(uw_hw['Load_MWh'].mean().round(1)) + ' MWh, Max=' + str(uw_hw['Load_MWh'].max().round(1)) + ' MWh'), linewidth=3)\n",
    "    plt.legend(loc='upper center', facecolor='white', framealpha=1)\n",
    "    plt.title('Unweighted HW Loads in ' + ba_to_process)\n",
    "    \n",
    "    plt.subplot(223)\n",
    "    plt.hist(pw_hw['T2_PW'], bins=25, density=True, histtype='step', edgecolor = 'r', label=('Mean=' + str(pw_hw['T2_PW'].mean().round(1)) + '$^\\circ$F, Max=' + str(pw_hw['T2_PW'].max().round(1)) + '$^\\circ$F'), linewidth=3)\n",
    "    plt.legend(loc='upper center', facecolor='white', framealpha=1)\n",
    "    plt.title('Pop-Weighted HW Temperatures in ' + ba_to_process)\n",
    "    \n",
    "    plt.subplot(224)\n",
    "    plt.hist(pw_hw['Load_MWh'], bins=25, density=True, histtype='step', edgecolor = 'b', label=('Mean=' + str(pw_hw['Load_MWh'].mean().round(1)) + ' MWh, Max=' + str(pw_hw['Load_MWh'].max().round(1)) + ' MWh'), linewidth=3)\n",
    "    plt.legend(loc='upper center', facecolor='white', framealpha=1)\n",
    "    plt.title('Pop-Weighted HW Loads in ' + ba_to_process)\n",
    "    \n",
    "    # If the \"save_images\" flag is set to true then save the plot to a .png file:\n",
    "    if save_images == True:\n",
    "       plt.savefig(os.path.join(image_output_dir, (ba_to_process + '_Heat_Wave_T_and_Load_Distributions_' + str(start_year) + '_to_' + str(end_year) + '.png')), \n",
    "                   dpi=image_resolution, bbox_inches='tight', facecolor='white')\n",
    "       plt.close()\n",
    "        \n",
    "    return pw_hw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5e995951-8032-44aa-9576-fb983154099b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_UTC</th>\n",
       "      <th>T2_UW</th>\n",
       "      <th>T2_PW</th>\n",
       "      <th>T2_Min</th>\n",
       "      <th>T2_Max</th>\n",
       "      <th>Load_MWh</th>\n",
       "      <th>UW_HW</th>\n",
       "      <th>PW_HW</th>\n",
       "      <th>Joint_HW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4872</th>\n",
       "      <td>1980-07-22 00:00:00</td>\n",
       "      <td>89.29</td>\n",
       "      <td>87.16</td>\n",
       "      <td>61.30</td>\n",
       "      <td>110.34</td>\n",
       "      <td>39771.33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4873</th>\n",
       "      <td>1980-07-22 01:00:00</td>\n",
       "      <td>87.13</td>\n",
       "      <td>84.94</td>\n",
       "      <td>60.49</td>\n",
       "      <td>108.86</td>\n",
       "      <td>40757.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4874</th>\n",
       "      <td>1980-07-22 02:00:00</td>\n",
       "      <td>84.11</td>\n",
       "      <td>82.04</td>\n",
       "      <td>59.49</td>\n",
       "      <td>105.48</td>\n",
       "      <td>40545.27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4875</th>\n",
       "      <td>1980-07-22 03:00:00</td>\n",
       "      <td>77.88</td>\n",
       "      <td>75.80</td>\n",
       "      <td>57.79</td>\n",
       "      <td>98.28</td>\n",
       "      <td>39830.95</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4876</th>\n",
       "      <td>1980-07-22 04:00:00</td>\n",
       "      <td>73.40</td>\n",
       "      <td>72.44</td>\n",
       "      <td>54.61</td>\n",
       "      <td>94.15</td>\n",
       "      <td>38648.80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348043</th>\n",
       "      <td>2019-09-14 19:00:00</td>\n",
       "      <td>85.57</td>\n",
       "      <td>87.82</td>\n",
       "      <td>64.87</td>\n",
       "      <td>102.09</td>\n",
       "      <td>27963.74</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348044</th>\n",
       "      <td>2019-09-14 20:00:00</td>\n",
       "      <td>87.32</td>\n",
       "      <td>89.26</td>\n",
       "      <td>65.89</td>\n",
       "      <td>103.78</td>\n",
       "      <td>29490.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348045</th>\n",
       "      <td>2019-09-14 21:00:00</td>\n",
       "      <td>88.34</td>\n",
       "      <td>89.95</td>\n",
       "      <td>66.60</td>\n",
       "      <td>104.86</td>\n",
       "      <td>31126.48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348046</th>\n",
       "      <td>2019-09-14 22:00:00</td>\n",
       "      <td>88.43</td>\n",
       "      <td>89.74</td>\n",
       "      <td>66.90</td>\n",
       "      <td>105.33</td>\n",
       "      <td>32474.34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348047</th>\n",
       "      <td>2019-09-14 23:00:00</td>\n",
       "      <td>87.63</td>\n",
       "      <td>88.65</td>\n",
       "      <td>66.78</td>\n",
       "      <td>105.21</td>\n",
       "      <td>33361.76</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13656 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Time_UTC  T2_UW  T2_PW  T2_Min  T2_Max  Load_MWh  UW_HW  \\\n",
       "4872    1980-07-22 00:00:00  89.29  87.16   61.30  110.34  39771.33      1   \n",
       "4873    1980-07-22 01:00:00  87.13  84.94   60.49  108.86  40757.79      1   \n",
       "4874    1980-07-22 02:00:00  84.11  82.04   59.49  105.48  40545.27      1   \n",
       "4875    1980-07-22 03:00:00  77.88  75.80   57.79   98.28  39830.95      1   \n",
       "4876    1980-07-22 04:00:00  73.40  72.44   54.61   94.15  38648.80      1   \n",
       "...                     ...    ...    ...     ...     ...       ...    ...   \n",
       "348043  2019-09-14 19:00:00  85.57  87.82   64.87  102.09  27963.74      0   \n",
       "348044  2019-09-14 20:00:00  87.32  89.26   65.89  103.78  29490.05      0   \n",
       "348045  2019-09-14 21:00:00  88.34  89.95   66.60  104.86  31126.48      0   \n",
       "348046  2019-09-14 22:00:00  88.43  89.74   66.90  105.33  32474.34      0   \n",
       "348047  2019-09-14 23:00:00  87.63  88.65   66.78  105.21  33361.76      0   \n",
       "\n",
       "        PW_HW  Joint_HW  \n",
       "4872        1         1  \n",
       "4873        1         1  \n",
       "4874        1         1  \n",
       "4875        1         1  \n",
       "4876        1         1  \n",
       "...       ...       ...  \n",
       "348043      1         0  \n",
       "348044      1         0  \n",
       "348045      1         0  \n",
       "348046      1         0  \n",
       "348047      1         0  \n",
       "\n",
       "[13656 rows x 9 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = plot_heat_wave_characteristics(ba_to_process = 'CISO', \n",
    "                                           start_year = 1980, \n",
    "                                           end_year = 2020, \n",
    "                                           base_year_start = 1980,\n",
    "                                           base_year_end = 1990,\n",
    "                                           weather_data_dir = weather_data_dir, \n",
    "                                           service_territory_data_dir = service_territory_data_dir, \n",
    "                                           population_data_dir = population_data_dir, \n",
    "                                           load_data_dir = load_data_dir, \n",
    "                                           data_output_dir = data_output_dir,\n",
    "                                           image_output_dir = image_output_dir, \n",
    "                                           image_resolution = 300, \n",
    "                                           save_images = True)\n",
    "\n",
    "output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4c5d3fc4-280f-433c-8c07-d893a1b79602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_uw_pw_t_distributions(ba_to_process: str, start_year: int, end_year: int, base_year_start: int, base_year_end: int,\n",
    "                               weather_data_dir: str, service_territory_data_dir: str, \n",
    "                               population_data_dir: str, load_data_dir: str, data_output_dir: str,\n",
    "                               image_output_dir: str, image_resolution: int, save_images=False):\n",
    "    \n",
    "    # Check to see if the output already exist and if not then process it:\n",
    "    if os.path.isfile(os.path.join(data_output_dir, (ba_to_process + '_Heat_Wave_Time_Series_' + str(start_year) + '_to_' + str(end_year) + '.csv'))) == True:\n",
    "       # Load in the pre-processed data:\n",
    "       met_df = pd.read_csv(os.path.join(data_output_dir, (ba_to_process + '_Heat_Wave_Time_Series_' + str(start_year) + '_to_' + str(end_year) + '.csv')))\n",
    "    else:\n",
    "       met_df = process_heat_wave_time_series(ba_to_process = ba_to_process, \n",
    "                                              start_year = start_year, \n",
    "                                              end_year = end_year, \n",
    "                                              base_year_start = base_year_start,\n",
    "                                              base_year_end = base_year_end,\n",
    "                                              weather_data_dir = weather_data_dir, \n",
    "                                              service_territory_data_dir = service_territory_data_dir, \n",
    "                                              population_data_dir = population_data_dir, \n",
    "                                              load_data_dir = load_data_dir, \n",
    "                                              data_output_dir = data_output_dir)\n",
    "    one_to_one = np.arange(0, 1000, 100)\n",
    "        \n",
    "    # Make the plot:\n",
    "    plt.figure(figsize=(25, 15))\n",
    "    plt.rcParams['font.size'] = 18\n",
    "    plt.scatter(met_df['T2_UW'], met_df['T2_PW'], s=10, facecolors='none', edgecolors='b', label=('Test'))\n",
    "    plt.plot(one_to_one, one_to_one, 'k', linewidth=3, label = '1:1')\n",
    "    plt.xlim(0, 120)\n",
    "    plt.ylim(0, 120)\n",
    "    plt.xlabel('Unweighted Temperature')\n",
    "    plt.ylabel('Population-Weighted Temperature')\n",
    "    plt.title('Weighting Effect in ' + ba_to_process + ' from ' + str(start_year) + ' to ' + str(end_year))\n",
    "    \n",
    "    # If the \"save_images\" flag is set to true then save the plot to a .png file:\n",
    "    if save_images == True:\n",
    "       plt.savefig(os.path.join(image_output_dir, (ba_to_process + '_Weighting_Effect_' + str(start_year) + '_to_' + str(end_year) + '.png')), \n",
    "                   dpi=image_resolution, bbox_inches='tight', facecolor='white')\n",
    "       plt.close()\n",
    "        \n",
    "    return met_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "53ef546e-09f5-46c1-bc1c-b378ef23a49b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_UTC</th>\n",
       "      <th>T2_UW</th>\n",
       "      <th>T2_PW</th>\n",
       "      <th>T2_Min</th>\n",
       "      <th>T2_Max</th>\n",
       "      <th>Load_MWh</th>\n",
       "      <th>UW_HW</th>\n",
       "      <th>PW_HW</th>\n",
       "      <th>Joint_HW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-01 00:00:00</td>\n",
       "      <td>51.76</td>\n",
       "      <td>57.85</td>\n",
       "      <td>33.57</td>\n",
       "      <td>65.79</td>\n",
       "      <td>24458.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-01-01 01:00:00</td>\n",
       "      <td>50.35</td>\n",
       "      <td>55.59</td>\n",
       "      <td>32.47</td>\n",
       "      <td>61.54</td>\n",
       "      <td>25630.37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-01-01 02:00:00</td>\n",
       "      <td>49.78</td>\n",
       "      <td>54.45</td>\n",
       "      <td>31.62</td>\n",
       "      <td>59.29</td>\n",
       "      <td>26350.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-01-01 03:00:00</td>\n",
       "      <td>49.29</td>\n",
       "      <td>53.73</td>\n",
       "      <td>30.56</td>\n",
       "      <td>58.42</td>\n",
       "      <td>27341.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-01-01 04:00:00</td>\n",
       "      <td>48.90</td>\n",
       "      <td>53.27</td>\n",
       "      <td>29.80</td>\n",
       "      <td>57.88</td>\n",
       "      <td>27805.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350635</th>\n",
       "      <td>2019-12-31 19:00:00</td>\n",
       "      <td>50.79</td>\n",
       "      <td>54.34</td>\n",
       "      <td>31.50</td>\n",
       "      <td>64.56</td>\n",
       "      <td>24445.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350636</th>\n",
       "      <td>2019-12-31 20:00:00</td>\n",
       "      <td>52.32</td>\n",
       "      <td>55.82</td>\n",
       "      <td>32.81</td>\n",
       "      <td>66.00</td>\n",
       "      <td>24391.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350637</th>\n",
       "      <td>2019-12-31 21:00:00</td>\n",
       "      <td>53.26</td>\n",
       "      <td>56.58</td>\n",
       "      <td>33.48</td>\n",
       "      <td>66.63</td>\n",
       "      <td>24449.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350638</th>\n",
       "      <td>2019-12-31 22:00:00</td>\n",
       "      <td>53.54</td>\n",
       "      <td>56.72</td>\n",
       "      <td>33.75</td>\n",
       "      <td>66.45</td>\n",
       "      <td>24723.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350639</th>\n",
       "      <td>2019-12-31 23:00:00</td>\n",
       "      <td>52.97</td>\n",
       "      <td>56.02</td>\n",
       "      <td>32.72</td>\n",
       "      <td>65.12</td>\n",
       "      <td>25248.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350640 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Time_UTC  T2_UW  T2_PW  T2_Min  T2_Max  Load_MWh  UW_HW  \\\n",
       "0       1980-01-01 00:00:00  51.76  57.85   33.57   65.79  24458.49      0   \n",
       "1       1980-01-01 01:00:00  50.35  55.59   32.47   61.54  25630.37      0   \n",
       "2       1980-01-01 02:00:00  49.78  54.45   31.62   59.29  26350.95      0   \n",
       "3       1980-01-01 03:00:00  49.29  53.73   30.56   58.42  27341.88      0   \n",
       "4       1980-01-01 04:00:00  48.90  53.27   29.80   57.88  27805.27      0   \n",
       "...                     ...    ...    ...     ...     ...       ...    ...   \n",
       "350635  2019-12-31 19:00:00  50.79  54.34   31.50   64.56  24445.51      0   \n",
       "350636  2019-12-31 20:00:00  52.32  55.82   32.81   66.00  24391.69      0   \n",
       "350637  2019-12-31 21:00:00  53.26  56.58   33.48   66.63  24449.65      0   \n",
       "350638  2019-12-31 22:00:00  53.54  56.72   33.75   66.45  24723.10      0   \n",
       "350639  2019-12-31 23:00:00  52.97  56.02   32.72   65.12  25248.45      0   \n",
       "\n",
       "        PW_HW  Joint_HW  \n",
       "0           0         0  \n",
       "1           0         0  \n",
       "2           0         0  \n",
       "3           0         0  \n",
       "4           0         0  \n",
       "...       ...       ...  \n",
       "350635      0         0  \n",
       "350636      0         0  \n",
       "350637      0         0  \n",
       "350638      0         0  \n",
       "350639      0         0  \n",
       "\n",
       "[350640 rows x 9 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = plot_uw_pw_t_distributions(ba_to_process = 'CISO', \n",
    "                                       start_year = 1980, \n",
    "                                       end_year = 2020, \n",
    "                                       base_year_start = 1980,\n",
    "                                       base_year_end = 1990,\n",
    "                                       weather_data_dir = weather_data_dir, \n",
    "                                       service_territory_data_dir = service_territory_data_dir, \n",
    "                                       population_data_dir = population_data_dir, \n",
    "                                       load_data_dir = load_data_dir, \n",
    "                                       data_output_dir = data_output_dir,\n",
    "                                       image_output_dir = image_output_dir, \n",
    "                                       image_resolution = 300, \n",
    "                                       save_images = True)\n",
    "\n",
    "output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a067f863-ae78-4b7e-9462-dfc8bbd9f854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.15_std",
   "language": "python",
   "name": "py3.9.15_std"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
